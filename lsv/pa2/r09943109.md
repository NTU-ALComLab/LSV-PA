# My Implementation
## Overview
### My implementation consists of five stages:

```
for each PO[i]  
    Extract cone[i] for PO[i]    
    Convert cone[i] to aig[i]  
    Convert aig[i] to CNFs     
    Initialize SAT solver   
    Manipulate SAT colver
```
## Detail
### 1. For the first stage:    
I use the following command to obtain cone for each PO.
```
Abc_NtkCreateCone(pNtk, Abc_ObjFanin0(pObj), Abc_ObjName(pObj), 0);
```
### 2. For the second stage:    
I use the following command to obatin the aig.  
Noticably, we should complement the PO if the original circuit'PO is complemented.   
```
Abc_NtkToDar(pNtkOn1, 0, 0);
bool isComplment = Abc_ObjFaninC0(pObj);
```
### 3. For the third stage: 
I use the following to obtain the CNF of the aig.   
Besides, I also duplicate the aig to represent postive cofactor and negative cofactor.
```
pCnfOn = Cnf_Derive(pMan, Aig_ManCoNum(pMan));
pCnfOff = Cnf_DataDup(pCnfOn);
Cnf_DataLift(pCnfOff, pCnfOn->nVars);
```
### 4. For the forth stage:     
I use the following commands to initialize SAT solver.  
First, I create an empty SAT solver.    
Second, I initialize the number of variables in this iteration.   
Finally, I add clause from cnf represented postive cofactor and negative cofactor, respectively.    
```
sat_solver *pSat = sat_solver_new();
sat_solver_setnvars(pSat, pCnfOn->nVars + pCnfOff->nVars + Aig_ManCiNum(pMan));
sat_solver_addclause(pSat, pCnfOn->pClauses[j], pCnfOn->pClauses[j + 1])
```
### 5. For the fifth stage:     
I use the following commands to manipulate SAT solver.  
First, I establish equivalence of each two variable pair.   
Second, I update the literal array which represents the assumption variable.    
Finally, I solve SAT to check postive unate and negative unate, respectively.   
```
sat_solver_add_buffer_enable(pSat, xOnI, xOffI, (pCnfOn->nVars + pCnfOff->nVars + j), 0);
vars[k] = toLitCond(curVar, 0);
int statusPos = sat_solver_solve(pSat, vars, vars + (ciNum + 4), 0, 0, 0, 0);
```

# Other topic
## 1. How does your implementation compared to the BDD- based command `print_unate` in ABC?
* We can see that the BDD-based `print_unate` is faster in most of the random case.   
However, in most of arithmetic cases e.g., arithmetic/sin.aig, it runs slower than our implementation.  
In fact, case arithmetic/sin.aig will time out for BDD-based `print_unate`.    
* Why BDD-based slow in arithmetic:  
Then, this may imply that it is harder for the BDD-based algorithm to deal with the arithmetic part.    
Besides, this can be explained by the fact that BDD-based algorithm will not fully utilized the intermediate nodes.     
It is easier for BDD-based algorithm to exponential blowup if a single circuit is too complicated.
* Why BDD-based fast in random control:     
On the contrary, BDD-based algorithm is suitable to deal with circuit e.g., mem_ctrl.aig since the circuit have less variable in each SAT solving process.


## 2. What are the differences between random control and arithmetic circuits? Which category is more challenging?

### Performace Analysis of **My lsv_print_pounate**
benchmark   | # PI          | # PO          | # avg var in CNF  | avg time for each PO     | total time
----------- | ------------- | ------------- | -------------     | ------------- | -------------
arbiter.aig  | 256 | 129 | 371.457 | 0.0371703 | 4.79492s
cavlc.aig | 10 | 11 | 41.3636 | 0.001979 | 0.021772
ctrl.aig | 7 | 26 | 10.5385 | 0.00137912 | 0.021772
dec.aig | 8 | 256 | 14 | 0.000935949 | 0.0.239606
i2c.aig | 147 | 142 | 19.4859 | 0.00109668 | 0.155731
int2float.aig | 11 | 7 | 27.2857 | 0.00226071 | 0.015827
mem_ctrl.aig | 1204 | 1231 | 93.6125 | 0.0966952 | 119.032
priority.aig | 128 | 8 | 178.125 | 0.0128751 | 0.103003
router.aig | 60 | 30 | 15.4 | 0.00144257 | 0.043279
adder.aig | 256 | 129 | 197.977 | 0.0210888 | 2.72045
bar.aig | 135 | 128 | 250 | 0.0193236 | 2.47342
max.aig | 512 | 130 | 1400.98 | 0.39636 | 51.5268
sin.aig | 24 | 25 | 2339.48 | 0.464921 | 11.623

* From this table, we can see that the arithmetic part is more challenging(the last four rows) since each PO's average computation time is longer.  
This may result from the fact that there are more variables in a CNF in arithmetic computation than random control.     
Which may lead to each SAT solver should check longer to prove **UNSAT**.